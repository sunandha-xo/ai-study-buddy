# ğŸ“ AI Study Buddy

An AI-powered study assistant that helps students learn more effectively using Retrieval-Augmented Generation (RAG). Upload your study materials and get instant answers, quizzes, flashcards, and summaries!

![AI Study Buddy](https://img.shields.io/badge/AI-Study%20Buddy-blue)
![Python](https://img.shields.io/badge/python-3.10+-blue.svg)
![FastAPI](https://img.shields.io/badge/FastAPI-0.109-green.svg)
![React](https://img.shields.io/badge/React-18.2-61dafb.svg)
![License](https://img.shields.io/badge/license-MIT-blue.svg)

---

## âœ¨ Features

- ğŸ“„ **Document Upload** - Upload PDFs and text files to create your knowledge base
- ğŸ’¬ **Smart Q&A** - Ask questions and get instant, context-aware answers from your materials
- ğŸ“ **Quiz Generation** - Auto-generate multiple-choice quizzes with customizable difficulty
- ğŸ´ **Flashcard Creation** - Generate flashcards for effective memorization
- ğŸ“Š **Smart Summaries** - Get comprehensive summaries of your study materials
- ğŸ§’ **ELI5 Explanations** - Complex concepts explained in simple terms
- ğŸ—‚ï¸ **Outline Generation** - Automatic hierarchical outlines of your documents
- ğŸ“ˆ **Progress Tracking** - Monitor your study progress and activity

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** - Modern Python web framework
- **Pinecone** - Vector database for semantic search
- **Groq** - Ultra-fast LLM inference (Llama 3.3 70B)
- **PyMuPDF** - PDF text extraction

### Frontend
- **React.js** - UI framework
- **Tailwind CSS** - Styling
- **Axios** - HTTP client

### AI/ML
- **RAG Architecture** - Retrieval-Augmented Generation
- **Llama Text Embeddings** - Semantic search
- **Llama 3.3 70B** - Answer generation

---

## ğŸ“‹ Prerequisites

- Python 3.10 or higher
- Node.js 16 or higher
- Pinecone account ([Sign up](https://www.pinecone.io/))
- Groq API key ([Get one](https://console.groq.com/))

---

## âš™ï¸ Installation

### 1. Clone the Repository

```bash
git clone https://github.com/sunandha-xo/ai-study-buddy.git
cd ai-study-buddy
```

### 2. Backend Setup

```bash
# Navigate to backend
cd backend

# Install dependencies
pip install -r requirements.txt

# Create .env file
cp .env.example .env
```

Edit `.env` with your API keys:

```env
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX_NAME=your_index_name
GROQ_API_KEY=your_groq_api_key
```

### 3. Frontend Setup

```bash
# Navigate to frontend
cd ../frontend

# Install dependencies
npm install
```

### 4. Set Up Pinecone Index

1. Go to [Pinecone Console](https://app.pinecone.io/)
2. Create a new index:
   - **Name**: `study-buddy` (or your choice)
   - **Dimensions**: `1024`
   - **Metric**: `cosine`
   - **Cloud**: `AWS` or `GCP`
   - **Region**: Choose nearest to you

---

## ğŸƒ Running the Application

### Start Backend

```bash
cd backend
python main.py
```

Backend will run on `http://localhost:8000`

### Start Frontend

In a new terminal:

```bash
cd frontend
npm start
```

Frontend will run on `http://localhost:3000`

---

## ğŸ“– Usage

### 1. Upload Documents

- Click **"Upload"** tab
- Select PDF or TXT files
- Wait for processing (5-30 seconds depending on file size)

### 2. Ask Questions

- Go to **"Q&A"** tab
- Type your question
- Get instant answers from your uploaded materials

### 3. Generate Quizzes

- Navigate to **"Quiz"** tab
- Select number of questions and difficulty
- Practice with auto-generated quizzes

### 4. Create Flashcards

- Go to **"Cards"** tab
- Generate flashcards from your documents
- Review key concepts

### 5. Get Summaries

- Click **"Summary"** tab
- View comprehensive summaries of your materials

---

## ğŸ“ Project Structure

```
ai-study-buddy/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ .env.example         # Environment variables template
â”‚   â””â”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/      # React components
â”‚   â”‚   â”œâ”€â”€ pages/          # Page components
â”‚   â”‚   â””â”€â”€ App.js          # Main app component
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json        # Node dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸ”§ API Endpoints

| Endpoint | Method | Description |
|----------|--------|-------------|
| `/upload` | POST | Upload and process documents |
| `/ask` | POST | Ask questions about documents |
| `/generate-quiz` | POST | Generate practice quizzes |
| `/generate-flashcards` | GET | Create flashcards |
| `/generate-summary` | GET | Get document summaries |
| `/explain-eli5` | POST | Get simple explanations |
| `/generate-outline` | GET | Create document outlines |
| `/progress` | GET | View study progress |

### Example API Call

```bash
# Upload a document
curl -X POST "http://localhost:8000/upload" \
  -F "file=@textbook.pdf"

# Ask a question
curl -X POST "http://localhost:8000/ask" \
  -H "Content-Type: application/json" \
  -d '{"question": "What is machine learning?"}'
```

---

## ğŸ¯ How It Works

### RAG Pipeline

```
1. Document Upload â†’ Text Extraction â†’ Chunking
                                         â†“
2. Chunk Embeddings â† Pinecone Inference API
                                         â†“
3. Store Vectors â†’ Pinecone Vector DB
                                         â†“
4. User Question â†’ Question Embedding
                                         â†“
5. Semantic Search â†’ Retrieve Relevant Chunks
                                         â†“
6. Context + Question â†’ Groq LLM â†’ Answer
```

### Key Components

**Embeddings**: Convert text to 1024-dimensional vectors using `llama-text-embed-v2`

**Vector Search**: Find semantically similar content using cosine similarity

**LLM Generation**: Generate natural language responses using Llama 3.3 70B

---

## ğŸ› Troubleshooting

### Backend won't start

```bash
# Check Python version
python --version  # Should be 3.10+

# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### API key errors

- Verify keys in `.env` file
- Check Pinecone index name matches
- Ensure API keys are active

### Upload fails

- Check file size (max 50MB recommended)
- Ensure PDF is text-based, not scanned
- Try uploading smaller files first

### Slow processing

- Large files (10+ pages) take 30-60 seconds
- This is normal for embedding generation
- Check console logs for progress

---

## ğŸš§ Known Limitations

- Maximum file size: 50MB (configurable)
- PDF processing works best with text-based PDFs
- Scanned documents need OCR (not yet implemented)
- Memory usage increases with large documents

---

## ğŸ—ºï¸ Roadmap

### Upcoming Features

- [ ] Support for DOCX, PPTX files
- [ ] OCR for scanned documents
- [ ] Multi-document search
- [ ] User authentication
- [ ] Study analytics dashboard
- [ ] Mobile app
- [ ] Spaced repetition system
- [ ] Collaborative study groups

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how you can help:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [Pinecone](https://www.pinecone.io/) - Vector database
- [Groq](https://groq.com/) - Fast LLM inference
- [FastAPI](https://fastapi.tiangolo.com/) - Backend framework
- [React](https://react.dev/) - Frontend framework

---

## â­ Star This Repo!

If you find this project helpful, please give it a star! â­

---

<div align="center">

**Built with â¤ï¸ for students everywhere**

[Report Bug](https://github.com/sunandha-xo/ai-study-buddy/issues) â€¢ [Request Feature](https://github.com/sunandha-xo/ai-study-buddy/issues)

</div>